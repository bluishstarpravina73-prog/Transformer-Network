{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# BULLETPROOF TRANSFORMER TIME SERIES FORECASTING\n",
        "# ==========================================================\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Load Dataset\n",
        "# -----------------------------\n",
        "data = sm.datasets.get_rdataset(\"AirPassengers\").data\n",
        "series = data['value'].values.astype(float)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Parameters (SAFE for small dataset)\n",
        "# -----------------------------\n",
        "SEQ_LEN = 12\n",
        "FORECAST_HORIZON = 6\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Train-Test Split (Guaranteed Valid)\n",
        "# -----------------------------\n",
        "split_index = int(len(series) * 0.8)\n",
        "\n",
        "train_series = series[:split_index]\n",
        "test_series = series[split_index-SEQ_LEN:]   # overlap included\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Scaling\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "train_scaled = scaler.fit_transform(train_series.reshape(-1,1))\n",
        "test_scaled = scaler.transform(test_series.reshape(-1,1))\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Create Sequences\n",
        "# -----------------------------\n",
        "def create_sequences(data, seq_length, horizon):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length - horizon + 1):\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length:i+seq_length+horizon])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_train, y_train = create_sequences(train_scaled, SEQ_LEN, FORECAST_HORIZON)\n",
        "X_test, y_test = create_sequences(test_scaled, SEQ_LEN, FORECAST_HORIZON)\n",
        "\n",
        "# Safety check\n",
        "if len(X_test) == 0:\n",
        "    raise ValueError(\"Test set too small. Reduce SEQ_LEN or FORECAST_HORIZON.\")\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.squeeze(), dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test.squeeze(), dtype=torch.float32)\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape :\", X_test.shape)\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Positional Encoding\n",
        "# -----------------------------\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=500):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
        "                             (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Transformer Model\n",
        "# -----------------------------\n",
        "class TimeSeriesTransformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        d_model = 64\n",
        "        self.input_proj = nn.Linear(1, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=4,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
        "        self.fc_out = nn.Linear(d_model, FORECAST_HORIZON)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer(x)\n",
        "        x = x[:, -1, :]\n",
        "        return self.fc_out(x)\n",
        "\n",
        "model = TimeSeriesTransformer()\n",
        "\n",
        "# -----------------------------\n",
        "# 8. Training\n",
        "# -----------------------------\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "EPOCHS = 120\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train)\n",
        "    loss = criterion(output, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# -----------------------------\n",
        "# 9. Evaluation\n",
        "# -----------------------------\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test).cpu().numpy()\n",
        "\n",
        "# Inverse scaling\n",
        "pred_inv = scaler.inverse_transform(predictions.reshape(-1,1)).reshape(predictions.shape)\n",
        "y_test_inv = scaler.inverse_transform(y_test.numpy().reshape(-1,1)).reshape(y_test.shape)\n",
        "\n",
        "rmse = math.sqrt(mean_squared_error(y_test_inv.flatten(), pred_inv.flatten()))\n",
        "mae = mean_absolute_error(y_test_inv.flatten(), pred_inv.flatten())\n",
        "\n",
        "mase_denom = np.mean(np.abs(train_series[1:] - train_series[:-1]))\n",
        "mase = mae / mase_denom\n",
        "\n",
        "print(\"\\n===== Transformer Performance =====\")\n",
        "print(\"RMSE :\", round(rmse,4))\n",
        "print(\"MAE  :\", round(mae,4))\n",
        "print(\"MASE :\", round(mase,4))\n",
        "\n",
        "# -----------------------------\n",
        "# 10. SARIMA Baseline\n",
        "# -----------------------------\n",
        "sarima = sm.tsa.SARIMAX(train_series,\n",
        "                        order=(1,1,1),\n",
        "                        seasonal_order=(1,1,1,12))\n",
        "sarima_fit = sarima.fit(disp=False)\n",
        "sarima_forecast = sarima_fit.forecast(steps=len(series)-split_index)\n",
        "\n",
        "rmse_s = math.sqrt(mean_squared_error(series[split_index:], sarima_forecast))\n",
        "mae_s = mean_absolute_error(series[split_index:], sarima_forecast)\n",
        "mase_s = mae_s / mase_denom\n",
        "\n",
        "print(\"\\n===== SARIMA Performance =====\")\n",
        "print(\"RMSE :\", round(rmse_s,4))\n",
        "print(\"MAE  :\", round(mae_s,4))\n",
        "print(\"MASE :\", round(mase_s,4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoyZN5LQQK4c",
        "outputId": "5f3f6cca-6afd-4936-e871-8192e76437ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: torch.Size([98, 12, 1])\n",
            "Test shape : torch.Size([24, 12, 1])\n",
            "\n",
            "===== Transformer Performance =====\n",
            "RMSE : 78.3183\n",
            "MAE  : 61.2243\n",
            "MASE : 2.9069\n",
            "\n",
            "===== SARIMA Performance =====\n",
            "RMSE : 30.142\n",
            "MAE  : 23.5557\n",
            "MASE : 1.1184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H0aduEKOQw97"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}